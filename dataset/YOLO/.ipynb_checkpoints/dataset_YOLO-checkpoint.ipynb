{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5f7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import csv\n",
    "\n",
    "# import xml.etree.ElementTree as Et\n",
    "# from xml.etree.ElementTree import Element, ElementTree\n",
    "# from PIL import Image\n",
    "\n",
    "# import json\n",
    "\n",
    "# from xml.etree.ElementTree import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "97e0df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://deepbaksuvision.github.io/Modu_ObjectDetection/posts/03_01_dataloader.html\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import os.path as osp\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "\n",
    "from Format import YOLO as cvtYOLO\n",
    "from Format import VOC as cvtVOC\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "DATA_ROOT = osp.join(\"./\", \"data/fire/\")\n",
    "\n",
    "def pad_to_square(img, pad_value):\n",
    "    c, h, w = img.shape\n",
    "    dim_diff = np.abs(h - w)\n",
    "    # (upper / left) padding and (lower / right) padding\n",
    "    pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2\n",
    "    # Determine padding\n",
    "    pad = (0, 0, pad1, pad2) if h <= w else (pad1, pad2, 0, 0)\n",
    "    # Add padding\n",
    "    img = F.pad(img, pad, \"constant\", value=pad_value)\n",
    "\n",
    "    return img, pad\n",
    "\n",
    "def resize(image, size):\n",
    "    image = F.interpolate(image.unsqueeze(0), size=size, mode=\"nearest\").squeeze(0)\n",
    "    return image\n",
    "\n",
    "\n",
    "class ImageFolder(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.files = sorted(glob.glob(\"%s/*.*\" % folder_path))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_path = self.files[index % len(self.files)]\n",
    "        img = np.array(\n",
    "            Image.open(img_path).convert('RGB'),\n",
    "            dtype=np.uint8)\n",
    "\n",
    "        # Label Placeholder\n",
    "        boxes = np.zeros((1, 5))\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            img, _ = self.transform((img, boxes))\n",
    "\n",
    "        return img_path, img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, resize=448, class_path='./fire.name'):\n",
    "\n",
    "      self.root = root\n",
    "      self.transform = transform\n",
    "      self.target_transform = target_transform\n",
    "      self.train = train\n",
    "      self.resize_factor = resize\n",
    "      self.class_path = class_path\n",
    "      \n",
    "\n",
    "      with open(class_path) as f:\n",
    "        self.classes = f.read().splitlines()\n",
    "  \n",
    "      self.image_dir = osp.join(DATA_ROOT, 'imgs/')\n",
    "      self.annopath_dir = osp.join(DATA_ROOT, 'annotations/')\n",
    "\n",
    "      self.batch_count = 0\n",
    "\n",
    "      self.data = self.cvtData()\n",
    "      \n",
    "      self.image_ids = os.listdir(self.image_dir)\n",
    "      self.annotation_ids = os.listdir(self.annopath_dir)\n",
    "      ##self.labeled_ids_len = len(self.labeled_ids)\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.image_ids[index]\n",
    "        img_path = osp.join(self.image_dir,img_id)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "\n",
    "        try:\n",
    "            key = list(self.data[index].keys())[0]\n",
    "            target = self.data[index][key]\n",
    "            semi = np.array([1])\n",
    "            \n",
    "        except:\n",
    "            semi = np.array([0])\n",
    "            target = np.zeros([1,5]) \n",
    "\n",
    "        current_size = img.size\n",
    "        \n",
    "        # -----------\n",
    "        #  Transform\n",
    "        # -----------\n",
    "        if self.transform is not None:\n",
    "          img = self.transform(img)\n",
    "          \n",
    "        if self.target_transform is not None:\n",
    "        # Future works\n",
    "          pass\n",
    "          \n",
    "         \n",
    "        return  img, target, semi, current_size \n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.image_ids))\n",
    "    \n",
    "    \n",
    "    def cvtData(self):\n",
    "\n",
    "      result = []\n",
    "      voc = cvtVOC()\n",
    "\n",
    "      yolo = cvtYOLO(os.path.abspath(self.class_path))\n",
    "      flag, self.dict_data =voc.parse(os.path.join(self.annopath_dir))\n",
    "\n",
    "      try:\n",
    "        if flag:\n",
    "          flag, data =yolo.generate(self.dict_data)\n",
    "\n",
    "          keys = list(data.keys())\n",
    "#           keys = sorted(keys, key=lambda key: int(key.split(\"_\")[-1]))\n",
    "\n",
    "          for key in keys:\n",
    "            contents = list(filter(None, data[key].split(\"\\n\")))\n",
    "            target = []\n",
    "            for i in range(len(contents)):\n",
    "              tmp = contents[i]\n",
    "              tmp = tmp.split(\" \")\n",
    "              for j in range(len(tmp)):\n",
    "                tmp[j] = float(tmp[j])\n",
    "              target.append(tmp)\n",
    "            result.append({key : target})\n",
    "\n",
    "        return result\n",
    "\n",
    "      except Exception as e:\n",
    "        raise RuntimeError(\"Error : {}\".format(e))\n",
    "        \n",
    "\n",
    "def detection_collate(batch):\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    sizes = []\n",
    "    semis = []\n",
    "\n",
    "    for sample in batch:\n",
    "        imgs.append(torch.from_numpy(sample[0]))\n",
    "        semis.append(torch.from_numpy(sample[2]))\n",
    "        sizes.append(sample[3])\n",
    "        \n",
    "        np_label = np.zeros((7, 7, 6), dtype=np.float32)\n",
    "        for object in sample[1]:\n",
    "            objectness = 1\n",
    "            classes = object[0]\n",
    "            x_ratio = object[1]\n",
    "            y_ratio = object[2]\n",
    "            w_ratio = object[3]\n",
    "            h_ratio = object[4]\n",
    "\n",
    "            scale_factor = (1 / 7)\n",
    "            grid_x_index = int(x_ratio // scale_factor)\n",
    "            grid_y_index = int(y_ratio // scale_factor)\n",
    "            x_offset = (x_ratio / scale_factor) - grid_x_index\n",
    "            y_offset = (y_ratio / scale_factor) - grid_y_index\n",
    "\n",
    "            np_label[grid_x_index][grid_y_index] = np.array([objectness, x_offset, y_offset, w_ratio, h_ratio, classes])\n",
    "\n",
    "        label = torch.from_numpy(np_label)\n",
    "        targets.append(label)\n",
    "    torch_imgs = torch.stack(imgs, 0)\n",
    "    torch_target = torch.stack(targets, 0)\n",
    "    return torch_imgs, torch_target, semis, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212b408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b060d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649b18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
